{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geoplotlib\n",
    "\n",
    "TRACE_DATA = './car-bus-simulation/output/events_lat_long.csv'\n",
    "COLUMNS = ['time', 'action', 'vid', 'lat', 'lon']\n",
    "\n",
    "# Define input size number of rows to be read from the csv into the pandas dataframe\n",
    "UNITY=1\n",
    "VID='4858_52'#'6311_1'\n",
    "SMALL=1000\n",
    "MEDIUM=5000000\n",
    "LARGE=None\n",
    "INPUT_SIZE=SMALL\n",
    "\n",
    "mdf = pd.read_csv(TRACE_DATA, nrows=INPUT_SIZE, names=COLUMNS, delimiter=\";\", header=None)\n",
    "       \n",
    "# All data points from a given vehicle id\n",
    "def filter_by_id(dataframe, id):\n",
    "    return dataframe.loc[dataframe['vid'] == id]\n",
    "\n",
    "# The first time a vehicle id registered an action in the simulation\n",
    "def origin(dataframe,id):\n",
    "    return filter_by_id(dataframe, id).iloc[[0]]\n",
    "        \n",
    "# The last time a vehicle id registered an action in the simulation\n",
    "def destiny(dataframe, id):\n",
    "    return filter_by_id(dataframe, id).iloc[[-1]]\n",
    "\n",
    "tool_tip = lambda x: 'time: ' + str(x[\"time\"]) + ', lat: ' + str(x[\"lat\"]) + ', lon: ' + str(x[\"lon\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import heapq \n",
    "import pickle\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import dateutil\n",
    "import datetime \n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from historical.readData.estimateData3 import read\n",
    "\n",
    "from historical.readData.estimateData3 import read\n",
    "from historical.readData.estimateData3 import search_travels\n",
    "from historical.readData.estimateData3 import estimate\n",
    "from historical.readData.estimateData3 import stops_distance\n",
    "\n",
    "from historical.readData.travels3 import haversine2\n",
    "\n",
    "def calcula_dist_shape(selec_linhas):\n",
    "    distance_all_shapes = {}\n",
    "    # print 'Calculando distancias dos shapes'\n",
    "    '''calcula todas as distancias dos shapes'''\n",
    "    \n",
    "    pth_files_GTFS = \"../historical/readData/dados/gtfs/\"        \n",
    "        \n",
    "    trips = pd.read_csv(pth_files_GTFS + 'trips.txt', sep=',')\n",
    "    shapes = pd.read_csv(pth_files_GTFS + 'shapes.txt', sep=',')\n",
    "    \n",
    "    for l, trip_id in enumerate(selec_linhas):\n",
    "\n",
    "        trip = trips[trips.trip_id == trip_id]\n",
    "        trip_shape = shapes[shapes['shape_id'].isin(trip['shape_id'])]\n",
    "        shapelat = trip_shape.shape_pt_lat.tolist()\n",
    "        shapelon = trip_shape.shape_pt_lon.tolist()\n",
    "\n",
    "        # distancias dos shapes\n",
    "        lon1 = shapelon[0]\n",
    "        lat1 = shapelat[0]\n",
    "        totalcal = [0.]\n",
    "        dist = [0.]\n",
    "        for lat2, lon2 in zip(shapelat[1:], shapelon[1:]):\n",
    "            d = haversine2(lat1, lon1, lat2, lon2)\n",
    "            d = d * 1000\n",
    "            dist.append(d)\n",
    "            totalcal.append(totalcal[-1] + d)\n",
    "            lat1 = lat2\n",
    "            lon1 = lon2\n",
    "        distance_all_shapes[trip_id] = [shapelat, shapelon, totalcal]\n",
    "    return distance_all_shapes\n",
    "\n",
    "def stops_distance(linha):\n",
    "\n",
    "    distances = calcula_dist_shape([linha])\n",
    "    totalcal = distances[linha][2]\n",
    "    \n",
    "    pth_files_GTFS = \"../historical/readData/dados/gtfs/\"\n",
    "    \n",
    "\n",
    "    trips = pd.read_csv(pth_files_GTFS + 'trips.txt', sep=',')\n",
    "    shapes = pd.read_csv(pth_files_GTFS + 'shapes.txt', sep=',')\n",
    "    stops = pd.read_csv(pth_files_GTFS + 'stops.txt', sep=',')\n",
    "    stopid = pd.read_csv(pth_files_GTFS + 'stop_times.txt', sep=',')   \n",
    "\n",
    "    ida = trips[trips.trip_id == linha]\n",
    "    shapeida = shapes[shapes['shape_id'].isin(ida['shape_id'])]\n",
    "    idalat = shapeida.shape_pt_lat.tolist()\n",
    "    idalon = shapeida.shape_pt_lon.tolist()\n",
    "    total = shapeida.shape_dist_traveled.tolist()\n",
    "\n",
    "    temp1 = stopid[stopid.trip_id == linha]\n",
    "    stopsida = stops[stops['stop_id'].isin(temp1['stop_id'])]\n",
    "    stopsida = stopsida.set_index('stop_id')\n",
    "    stopsida = stopsida.reindex(index=temp1['stop_id'])\n",
    "\n",
    "    stopslat = stopsida.stop_lat.tolist()\n",
    "    stopslon = stopsida.stop_lon.tolist()\n",
    "\n",
    "    dpontos = [None] * len(stopslat)\n",
    "    index = 0\n",
    "    lat = idalat\n",
    "    lon = idalon\n",
    "    total = 0\n",
    "    p = ['depois'] * len(stopslat)\n",
    "    for latb, lonb, i in zip(stopslat, stopslon, range(len(stopslat))):\n",
    "        lat = lat[index:]\n",
    "        lon = lon[index:]\n",
    "        nn = haversine2(latb, lonb, np.array(lat), np.array(lon)) * 1000\n",
    "        index = nn.argmin()\n",
    "        total = total + index\n",
    "        if index == 0:\n",
    "            dpontos[i] = nn[index]\n",
    "#            descontardist = nn[index]\n",
    "        else:\n",
    "            if totalcal[total] >= totalcal[total - 1] + nn[index - 1]:\n",
    "                p[i] = 'antes'\n",
    "            dpontos[i] = totalcal[total - 1] + nn[index - 1]\n",
    "\n",
    "    mid_points = []\n",
    "#    mid_points.append(200)\n",
    "    p1 = dpontos[0]\n",
    "    for p2 in dpontos[1:]:\n",
    "        mid_points.append(p1 + (p2-p1)/2)\n",
    "        p1 = p2\n",
    "    dpontos = [i/1000. for i in dpontos]\n",
    "    mid_points = [i/1000. for i in mid_points]\n",
    "    # dpontos = [val-descontardist for val in dpontos]\n",
    "    # stopsida.reset_index(drop=True, inplace=True)\n",
    "    # stopsida['distancia'] = dpontos\n",
    "    # stopsida.sort_values('distancia',axis=0,inplace=True)\n",
    "    # stopsida.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # gmap = gmplot.GoogleMapPlotter(idalat[0], idalon[0], 19)\n",
    "    # gmap.marker(idalat[0],idalon[0], title='Test text')\n",
    "    # gmap.plot(idalat, idalon, 'blue')\n",
    "    # gmap.scatter(idalat, idalon, c='blue', size=10, marker=True, titles=totalcal)\n",
    "    # gmap.scatter(stopsida['stop_lat'].tolist(), stopsida['stop_lon'].tolist(), c='red', size=10, marker=True,\n",
    "    #             titles=[\"Ponto \" + str(i + 1) + \": dist: \" + str(stopsida['distancia'][i]) + ' ' + p[i] for i in\n",
    "    #                     range(len(dpontos))])\n",
    "\n",
    "    # gmap.draw('pontos.html')\n",
    "\n",
    "    return dpontos, mid_points\n",
    "\n",
    "def read(filedata,filerep):\n",
    "    df0 = pd.read_pickle(filedata, compression=None)\n",
    "    with open(filerep, 'rb') as handle:\n",
    "        reps = pickle.load(handle, encoding='latin1')\n",
    "    return df0, reps\n",
    "\n",
    "selected_line = ['8700-10-1']\n",
    "\n",
    "pth_files_GTFS = \"../historical/readData/dados/gtfs/\"\n",
    "\n",
    "trips = pd.read_csv(pth_files_GTFS + 'trips.txt', sep=',')\n",
    "shapes = pd.read_csv(pth_files_GTFS + 'shapes.txt', sep=',')\n",
    "stops = pd.read_csv(pth_files_GTFS + 'stops.txt', sep=',')\n",
    "stopid = pd.read_csv(pth_files_GTFS + 'stop_times.txt', sep=',')   \n",
    "\n",
    "periods = ['morning', 'm_peak', 'i_peak', 'a_peak', 'night']\n",
    "\n",
    "line = selected_line[0]\n",
    "pth_files_lines = \"../historical/readData/\"\n",
    "p, mp = stops_distance(line)\n",
    "df, reps = read(pth_files_lines + \"trips_\" + line + \".dsk\", pth_files_lines + \"interps_\" + line + \".rep\")   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer\n",
    "from geoplotlib.layers import BaseLayer\n",
    "from geoplotlib.layers import HotspotManager\n",
    "from geoplotlib.utils import BoundingBox\n",
    "from geoplotlib.core import BatchPainter\n",
    "import random\n",
    "import time\n",
    "\n",
    "# trajectories = df_temporal\n",
    "trajectories = mdf\n",
    "\n",
    "class DotDensityLayer(BaseLayer):\n",
    "\n",
    "    def __init__(self, data, color=None, point_size=2, f_tooltip=None):\n",
    "        \"\"\"Create a dot density map\n",
    "        :param data: data access object\n",
    "        :param color: color\n",
    "        :param point_size: point size\n",
    "        :param f_tooltip: function to return a tooltip string for a point\n",
    "        \"\"\"\n",
    "        self.frame_counter = 23\n",
    "        self.data = data\n",
    "        self.last = self.data.drop_duplicates(subset=['vid'], keep='first')\n",
    "        self.color = color\n",
    "        if self.color is None:\n",
    "            self.color = [255,0,0]\n",
    "        self.point_size = point_size\n",
    "        self.f_tooltip = f_tooltip\n",
    "\n",
    "        self.hotspots = HotspotManager()\n",
    "\n",
    "\n",
    "    def invalidate(self, proj):\n",
    "        self.last = self.data.loc[self.data['time'] == self.frame_counter]\n",
    "        lon_at = self.last['lon']\n",
    "        lat_at = self.last['lat']\n",
    "        \n",
    "        self.x, self.y = proj.lonlat_to_screen(lon_at, lat_at)\n",
    "        \n",
    "\n",
    "\n",
    "    def draw(self, proj, mouse_x, mouse_y, ui_manager):\n",
    "        self.painter = BatchPainter()\n",
    "        current = self.data.loc[self.data['time'] == self.frame_counter]\n",
    "        \n",
    "        self.last = pd.concat([self.last, current]).drop_duplicates(subset='vid', keep='last')\n",
    "        lon_at = self.last['lon']\n",
    "        lat_at = self.last['lat']\n",
    "        \n",
    "        x, y = proj.lonlat_to_screen(lon_at, lat_at)\n",
    "        \n",
    "        if self.f_tooltip:\n",
    "            for i in range(0, len(x)):\n",
    "                record = {k: self.data[k][i] for k in self.data.keys()}\n",
    "                self.hotspots.add_rect(x[i] - self.point_size, y[i] - self.point_size,\n",
    "                                       2*self.point_size, 2*self.point_size,\n",
    "                                       self.f_tooltip(record))\n",
    "\n",
    "        self.painter.set_color(self.color)\n",
    "        self.painter.points(x, y, 2*self.point_size, False)\n",
    "        \n",
    "        self.painter.batch_draw()\n",
    "        picked = self.hotspots.pick(mouse_x, mouse_y)\n",
    "        if picked:\n",
    "            ui_manager.tooltip(picked)\n",
    "        self.frame_counter += 1\n",
    "        #time.sleep(0.4)\n",
    "\n",
    "\n",
    "    def bbox(self):\n",
    "        return BoundingBox.from_points(lons=self.data['lon'], lats=self.data['lat'])\n",
    "        \n",
    "geoplotlib.add_layer(DotDensityLayer(trajectories))\n",
    "geoplotlib.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectories calculated in adds_dest_coordinates_small.csv, use force=True to recalculate\n"
     ]
    }
   ],
   "source": [
    "# input_size_to_human = \"small_\"\n",
    "if INPUT_SIZE in range(1, SMALL + 1):\n",
    "    input_size_to_human = \"small\"\n",
    "elif INPUT_SIZE in range(SMALL, MEDIUM + 1):\n",
    "    input_size_to_human = \"medium\"\n",
    "elif INPUT_SIZE == None or INPUT_SIZE > MEDIUM:\n",
    "    input_size_to_human = \"large\"\n",
    "else:\n",
    "    raise Exception(\"Invalid input size\")\n",
    "                    \n",
    "output_file =  (\"adds_dest_coordinates_%s.csv\" % input_size_to_human)\n",
    "\n",
    "def calculate_trajectories(force=False):\n",
    "    import os.path\n",
    "    if(force==False and os.path.exists(output_file)):\n",
    "        print(\"Trajectories calculated in %s, use force=True to recalculate\" % output_file)\n",
    "        return\n",
    "\n",
    "    counts = mdf.groupby(['vid'], as_index=False)\n",
    "\n",
    "    print(\"Input Size: %s\" % input_size_to_human)\n",
    "    print(\"Number of unique vehicles: %s\" % len(counts.count()))\n",
    "\n",
    "    def shift_lat_lon(df):\n",
    "        df.loc[:, 'dest_lat'] = df.shift(-1).loc[:, 'lat']\n",
    "        df.loc[:, 'dest_lon'] = df.shift(-1).loc[:, 'lon']\n",
    "        return df\n",
    "\n",
    "    res = counts.apply(shift_lat_lon)\n",
    "    res.sort_values(['vid','time'], inplace=True)\n",
    "    res.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(\"Writing to csv\")\n",
    "    res.to_csv(output_file, index=False)\n",
    "    print(\"Written to %s\" % output_file)\n",
    "    \n",
    "calculate_trajectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'adds_dest_coordinates.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-88fe94806c5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatapoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adds_dest_coordinates.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#filtered = datapoints[datapoints['dest_lat'].notnull()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgeoplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Oranges'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap_levels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_colorbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'adds_dest_coordinates.csv' does not exist"
     ]
    }
   ],
   "source": [
    "datapoints = pd.read_csv(\"adds_dest_coordinates.csv\", delimiter=\",\")\n",
    "#filtered = datapoints[datapoints['dest_lat'].notnull()]\n",
    "\n",
    "geoplotlib.kde(datapoints, bw=5, cmap='Oranges', cmap_levels=20, show_colorbar=True, alpha=170)\n",
    "\n",
    "geoplotlib.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
