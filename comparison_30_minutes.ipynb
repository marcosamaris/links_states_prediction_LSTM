{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Median of $n$ buses in a period of 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:53:06.325298Z",
     "start_time": "2019-10-25T18:53:03.978928Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import heapq \n",
    "import pickle\n",
    "%matplotlib inline\n",
    "    \n",
    "import plotnine as p9\n",
    "import matplotlib.pyplot as plt\n",
    "import dateutil\n",
    "import datetime \n",
    "from time import time\n",
    "import re\n",
    "from scipy import interpolate\n",
    "import timeit\n",
    "from dateutil.rrule import DAILY, rrule, MO, TU, WE, TH, FR\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge\n",
    "from sklearn import tree\n",
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from historical.readData.old.estimateData3 import read\n",
    "\n",
    "from historical.readData.old.estimateData3 import read\n",
    "from historical.readData.old.estimateData3 import search_travels\n",
    "from historical.readData.old.estimateData3 import estimate\n",
    "from historical.readData.old.estimateData3 import stops_distance\n",
    "\n",
    "from historical.readData.old.travels3 import haversine2\n",
    "\n",
    "def calcula_dist_shape(selec_linhas):\n",
    "    distance_all_shapes = {}\n",
    "    # print 'Calculando distancias dos shapes'\n",
    "    '''calcula todas as distancias dos shapes'''\n",
    "    \n",
    "    pth_files_GTFS = \"../data/gtfs/\"\n",
    "        \n",
    "    trips = pd.read_csv(pth_files_GTFS + 'trips.txt', sep=',')\n",
    "    shapes = pd.read_csv(pth_files_GTFS + 'shapes.txt', sep=',')\n",
    "    \n",
    "    for l, trip_id in enumerate(selec_linhas):\n",
    "\n",
    "        trip = trips[trips.trip_id == trip_id]\n",
    "        trip_shape = shapes[shapes['shape_id'].isin(trip['shape_id'])]\n",
    "        shapelat = trip_shape.shape_pt_lat.tolist()\n",
    "        shapelon = trip_shape.shape_pt_lon.tolist()\n",
    "\n",
    "        # distancias dos shapes\n",
    "        lon1 = shapelon[0]\n",
    "        lat1 = shapelat[0]\n",
    "        totalcal = [0.]\n",
    "        dist = [0.]\n",
    "        for lat2, lon2 in zip(shapelat[1:], shapelon[1:]):\n",
    "            d = haversine2(lat1, lon1, lat2, lon2)\n",
    "            d = d * 1000\n",
    "            dist.append(d)\n",
    "            totalcal.append(totalcal[-1] + d)\n",
    "            lat1 = lat2\n",
    "            lon1 = lon2\n",
    "        distance_all_shapes[trip_id] = [shapelat, shapelon, totalcal]\n",
    "    return distance_all_shapes\n",
    "\n",
    "def stops_distance(linha):\n",
    "\n",
    "    distances = calcula_dist_shape([linha])\n",
    "    totalcal = distances[linha][2]\n",
    "    \n",
    "    pth_files_GTFS = \"../data/gtfs/\"\n",
    "    \n",
    "\n",
    "    trips = pd.read_csv(pth_files_GTFS + 'trips.txt', sep=',')\n",
    "    shapes = pd.read_csv(pth_files_GTFS + 'shapes.txt', sep=',')\n",
    "    stops = pd.read_csv(pth_files_GTFS + 'stops.txt', sep=',')\n",
    "    stopid = pd.read_csv(pth_files_GTFS + 'stop_times.txt', sep=',')   \n",
    "\n",
    "    ida = trips[trips.trip_id == linha]\n",
    "    shapeida = shapes[shapes['shape_id'].isin(ida['shape_id'])]\n",
    "    idalat = shapeida.shape_pt_lat.tolist()\n",
    "    idalon = shapeida.shape_pt_lon.tolist()\n",
    "    total = shapeida.shape_dist_traveled.tolist()\n",
    "\n",
    "    temp1 = stopid[stopid.trip_id == linha]\n",
    "    stopsida = stops[stops['stop_id'].isin(temp1['stop_id'])]\n",
    "    stopsida = stopsida.set_index('stop_id')\n",
    "    stopsida = stopsida.reindex(index=temp1['stop_id'])\n",
    "\n",
    "    stopslat = stopsida.stop_lat.tolist()\n",
    "    stopslon = stopsida.stop_lon.tolist()\n",
    "\n",
    "    dpontos = [None] * len(stopslat)\n",
    "    index = 0\n",
    "    lat = idalat\n",
    "    lon = idalon\n",
    "    total = 0\n",
    "    p = ['depois'] * len(stopslat)\n",
    "    for latb, lonb, i in zip(stopslat, stopslon, range(len(stopslat))):\n",
    "        lat = lat[index:]\n",
    "        lon = lon[index:]\n",
    "        nn = haversine2(latb, lonb, np.array(lat), np.array(lon)) * 1000\n",
    "        index = nn.argmin()\n",
    "        total = total + index\n",
    "        if index == 0:\n",
    "            dpontos[i] = nn[index]\n",
    "#            descontardist = nn[index]\n",
    "        else:\n",
    "            if totalcal[total] >= totalcal[total - 1] + nn[index - 1]:\n",
    "                p[i] = 'antes'\n",
    "            dpontos[i] = totalcal[total - 1] + nn[index - 1]\n",
    "\n",
    "    mid_points = []\n",
    "#    mid_points.append(200)\n",
    "    p1 = dpontos[0]\n",
    "    for p2 in dpontos[1:]:\n",
    "        mid_points.append(p1 + (p2-p1)/2)\n",
    "        p1 = p2\n",
    "    dpontos = [i/1000. for i in dpontos]\n",
    "    mid_points = [i/1000. for i in mid_points]\n",
    "\n",
    "    return dpontos, mid_points\n",
    "\n",
    "def read(filedata,filerep):\n",
    "    df0 = pd.read_pickle(filedata, compression=None)\n",
    "    with open(filerep, 'rb') as handle:\n",
    "        reps = pickle.load(handle, encoding='latin1')\n",
    "    return df0, reps\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + datetime.timedelta(n)\n",
    "        \n",
    "def daterangeWD(start_date, end_date):\n",
    "  return rrule(DAILY, dtstart=start_date, until=end_date, byweekday=(MO,TU,WE,TH,FR))\n",
    "\n",
    "def hr_func(ts):\n",
    "    return ts.hour\n",
    "\n",
    "def minute_func(ts):\n",
    "    return ts.minute\n",
    "\n",
    "def second_func(ts):\n",
    "    return ts.second\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib agg \n",
    "\n",
    "pth_files_GTFS = \"../data/gtfs/\"\n",
    "\n",
    "trips = pd.read_csv(pth_files_GTFS + 'trips.txt', sep=',')\n",
    "shapes = pd.read_csv(pth_files_GTFS + 'shapes.txt', sep=',')\n",
    "stops = pd.read_csv(pth_files_GTFS + 'stops.txt', sep=',')\n",
    "stopid = pd.read_csv(pth_files_GTFS + 'stop_times.txt', sep=',')   \n",
    "\n",
    "periods = ['morning', 'm_peak', 'i_peak', 'a_peak', 'night']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:53:52.227959Z",
     "start_time": "2019-10-25T18:53:21.694213Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_line = ['8700-10-1']\n",
    "\n",
    "selected_line = [\n",
    "                '8700-10-1',                \n",
    "                '7545-10-1',\n",
    "                '7545-10-0',\n",
    "                '6450-10-1',\n",
    "                '6450-10-0',\n",
    "                '3301-10-1',\n",
    "#                 '3301-10-0',\n",
    "                '2290-10-1',\n",
    "                '2290-10-0',\n",
    "#                 '574J-10-1',\n",
    "#                 '574J-10-0',\n",
    "#                 '477P-10-1',\n",
    "                '477P-10-0',\n",
    "#                 '351F-10-1',\n",
    "#                 '351F-10-0'\n",
    "                ]\n",
    "selected_line = ['6450-10-0']\n",
    "\n",
    "MAPE_day = []\n",
    "\n",
    "for line in selected_line:\n",
    "#     line = selected_line[0]\n",
    "    p, mp = stops_distance(line)\n",
    "    pth_files_lines = \"../historical/readData/\"\n",
    "\n",
    "    ### Operação demorada\n",
    "    df, reps = read(pth_files_lines + \"trips_\" + line + \".dsk\", pth_files_lines + \"interps_\" + line + \".rep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T18:57:17.548311Z",
     "start_time": "2019-10-25T18:57:17.499236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car</th>\n",
       "      <th>numtravel</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>holiday</th>\n",
       "      <th>start</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>time</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>0.05535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>0.11812</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>0.17883</td>\n",
       "      <td>3.316667</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>0.50429</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>0.58227</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>0.96159</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>1.01292</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>1.48960</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>1.62704</td>\n",
       "      <td>6.066667</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>2.03243</td>\n",
       "      <td>7.033333</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>2.45983</td>\n",
       "      <td>8.550000</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>2.71761</td>\n",
       "      <td>10.216667</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>2.94465</td>\n",
       "      <td>11.183333</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>3.33585</td>\n",
       "      <td>12.366667</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>3.57740</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>3.74421</td>\n",
       "      <td>12.850000</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>3.83822</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>4.63904</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>5.10976</td>\n",
       "      <td>15.050000</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>5.42407</td>\n",
       "      <td>16.150000</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>5.44438</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>6.02244</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>6.41194</td>\n",
       "      <td>18.616667</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>6.43745</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>6.97067</td>\n",
       "      <td>20.516667</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>7.44402</td>\n",
       "      <td>21.650000</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>7.65691</td>\n",
       "      <td>23.316667</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>8.06312</td>\n",
       "      <td>24.716667</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>8.21130</td>\n",
       "      <td>24.916667</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>72365\\r</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:12:19</td>\n",
       "      <td>52.35</td>\n",
       "      <td>8.36902</td>\n",
       "      <td>25.116667</td>\n",
       "      <td>i_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417975</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>15.68387</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417976</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>15.73898</td>\n",
       "      <td>43.483333</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417977</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>16.09689</td>\n",
       "      <td>44.233333</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417978</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>16.26509</td>\n",
       "      <td>44.750000</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417979</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>16.40787</td>\n",
       "      <td>44.983333</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417980</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>16.49284</td>\n",
       "      <td>45.116667</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417981</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>16.76491</td>\n",
       "      <td>45.866667</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417982</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>16.87449</td>\n",
       "      <td>46.600000</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417983</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>16.97476</td>\n",
       "      <td>46.800000</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417984</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>17.03381</td>\n",
       "      <td>46.950000</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417985</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>17.18328</td>\n",
       "      <td>47.700000</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417986</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>17.23728</td>\n",
       "      <td>48.450000</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417987</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>17.32761</td>\n",
       "      <td>48.716667</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417988</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>17.41345</td>\n",
       "      <td>48.900000</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417989</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>17.50446</td>\n",
       "      <td>49.083333</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417990</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>17.73085</td>\n",
       "      <td>49.833333</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417991</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>17.80556</td>\n",
       "      <td>49.933333</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417992</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>18.31854</td>\n",
       "      <td>50.583333</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417993</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>18.40143</td>\n",
       "      <td>50.716667</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417994</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>18.47255</td>\n",
       "      <td>50.850000</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417995</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>18.55850</td>\n",
       "      <td>51.066667</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417996</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>18.83422</td>\n",
       "      <td>51.683333</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417997</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>19.04163</td>\n",
       "      <td>52.016667</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417998</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>19.39397</td>\n",
       "      <td>52.766667</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417999</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>19.43313</td>\n",
       "      <td>52.816667</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418000</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>19.71987</td>\n",
       "      <td>53.316667</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418001</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>19.77520</td>\n",
       "      <td>53.616667</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418002</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>20.11223</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418003</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>20.26358</td>\n",
       "      <td>54.533333</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418004</th>\n",
       "      <td>72383\\r</td>\n",
       "      <td>19786</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17:01:14</td>\n",
       "      <td>54.70</td>\n",
       "      <td>20.33860</td>\n",
       "      <td>54.700000</td>\n",
       "      <td>a_peak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2418005 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             car numtravel         day weekday holiday     start  travel_time  \\\n",
       "0        72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "1        72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "2        72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "3        72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "4        72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "5        72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "6        72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "7        72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "8        72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "9        72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "10       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "11       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "12       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "13       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "14       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "15       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "16       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "17       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "18       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "19       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "20       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "21       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "22       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "23       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "24       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "25       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "26       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "27       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "28       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "29       72365\\r         0  2017-01-01       6       1  11:12:19        52.35   \n",
       "...          ...       ...         ...     ...     ...       ...          ...   \n",
       "2417975  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417976  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417977  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417978  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417979  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417980  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417981  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417982  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417983  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417984  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417985  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417986  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417987  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417988  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417989  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417990  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417991  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417992  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417993  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417994  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417995  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417996  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417997  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417998  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2417999  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2418000  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2418001  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2418002  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2418003  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "2418004  72383\\r     19786  2017-09-30       5       0  17:01:14        54.70   \n",
       "\n",
       "         distance       time  period  \n",
       "0         0.05535   0.000000  i_peak  \n",
       "1         0.11812   1.650000  i_peak  \n",
       "2         0.17883   3.316667  i_peak  \n",
       "3         0.50429   4.066667  i_peak  \n",
       "4         0.58227   4.150000  i_peak  \n",
       "5         0.96159   4.666667  i_peak  \n",
       "6         1.01292   4.733333  i_peak  \n",
       "7         1.48960   5.400000  i_peak  \n",
       "8         1.62704   6.066667  i_peak  \n",
       "9         2.03243   7.033333  i_peak  \n",
       "10        2.45983   8.550000  i_peak  \n",
       "11        2.71761  10.216667  i_peak  \n",
       "12        2.94465  11.183333  i_peak  \n",
       "13        3.33585  12.366667  i_peak  \n",
       "14        3.57740  12.666667  i_peak  \n",
       "15        3.74421  12.850000  i_peak  \n",
       "16        3.83822  13.000000  i_peak  \n",
       "17        4.63904  14.500000  i_peak  \n",
       "18        5.10976  15.050000  i_peak  \n",
       "19        5.42407  16.150000  i_peak  \n",
       "20        5.44438  16.250000  i_peak  \n",
       "21        6.02244  17.333333  i_peak  \n",
       "22        6.41194  18.616667  i_peak  \n",
       "23        6.43745  19.100000  i_peak  \n",
       "24        6.97067  20.516667  i_peak  \n",
       "25        7.44402  21.650000  i_peak  \n",
       "26        7.65691  23.316667  i_peak  \n",
       "27        8.06312  24.716667  i_peak  \n",
       "28        8.21130  24.916667  i_peak  \n",
       "29        8.36902  25.116667  i_peak  \n",
       "...           ...        ...     ...  \n",
       "2417975  15.68387  43.250000  a_peak  \n",
       "2417976  15.73898  43.483333  a_peak  \n",
       "2417977  16.09689  44.233333  a_peak  \n",
       "2417978  16.26509  44.750000  a_peak  \n",
       "2417979  16.40787  44.983333  a_peak  \n",
       "2417980  16.49284  45.116667  a_peak  \n",
       "2417981  16.76491  45.866667  a_peak  \n",
       "2417982  16.87449  46.600000  a_peak  \n",
       "2417983  16.97476  46.800000  a_peak  \n",
       "2417984  17.03381  46.950000  a_peak  \n",
       "2417985  17.18328  47.700000  a_peak  \n",
       "2417986  17.23728  48.450000  a_peak  \n",
       "2417987  17.32761  48.716667  a_peak  \n",
       "2417988  17.41345  48.900000  a_peak  \n",
       "2417989  17.50446  49.083333  a_peak  \n",
       "2417990  17.73085  49.833333  a_peak  \n",
       "2417991  17.80556  49.933333  a_peak  \n",
       "2417992  18.31854  50.583333  a_peak  \n",
       "2417993  18.40143  50.716667  a_peak  \n",
       "2417994  18.47255  50.850000  a_peak  \n",
       "2417995  18.55850  51.066667  a_peak  \n",
       "2417996  18.83422  51.683333  a_peak  \n",
       "2417997  19.04163  52.016667  a_peak  \n",
       "2417998  19.39397  52.766667  a_peak  \n",
       "2417999  19.43313  52.816667  a_peak  \n",
       "2418000  19.71987  53.316667  a_peak  \n",
       "2418001  19.77520  53.616667  a_peak  \n",
       "2418002  20.11223  54.283333  a_peak  \n",
       "2418003  20.26358  54.533333  a_peak  \n",
       "2418004  20.33860  54.700000  a_peak  \n",
       "\n",
       "[2418005 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T23:03:21.500774Z",
     "start_time": "2019-10-08T23:03:12.715678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 8.745420275313107\n",
      "After: 13.983902250267427\n",
      "median_LR_after: 12.069013044826184\n",
      "median_Tree_after: 17.433925172530618\n",
      "median_Lasso_after: 12.54823803523942\n",
      "Future: 14.555437910966928\n",
      "median_LR_future: 10.217191442885868\n",
      "median_Tree_future: 15.34808290083754\n",
      "median_Lasso_future: 12.294728662441758\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(MAPE_day,columns=['line', 'link', 'day', 'time', 'N-travel', 'median', 'MAPE', 'travels_time', 'errors'])\n",
    "pd.DataFrame(data).to_html('html/data-30M_median_' + select_day + '.html')  \n",
    "        \n",
    "data = data.loc[data['MAPE'] != 0] \n",
    "# data = data.loc[(data['errors'] != 'median_LR_after') & (data['errors'] != 'median_Tree_after') &\n",
    "#         (data['errors'] != 'median_LR_future') & (data['errors'] != 'median_Tree_future')]\n",
    "fig = (\n",
    "        p9.ggplot(data, p9.aes(x = 'errors', y ='MAPE', group='errors', colors='errors')) +\n",
    "        p9.geom_boxplot( outlier_shape = \"\") +\n",
    "        p9.scale_y_continuous(limits =  (0, 50)) +        \n",
    "        p9.stat_boxplot(geom ='errorbar')  +        \n",
    "        p9.theme_bw() +\n",
    "        p9.theme(figure_size = (8, 12)) +\n",
    "        p9.facet_wrap('~line', ncol = 3) +\n",
    "        p9.labs(title = 'MAPE of the lines in the day ' + select_day ) +\n",
    "        p9.theme(figure_size = (18, 24))  +\n",
    "        p9.theme(axis_text_x = p9.element_text(angle=90)) \n",
    "    )\n",
    "p9.ggsave(fig, 'png/Boxplot' + '_' + select_day + '_30M_median.png')  \n",
    "p9.ggsave(fig, 'pdf/Boxplot' + '_' + select_day + '_30M_median.pdf')\n",
    "\n",
    "for i in data['errors'].unique():\n",
    "    print(i + ': ' + str(data.loc[data['errors'] == i]['MAPE'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Median of $n$ buses in a period of 60 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:44:53.238932Z",
     "start_time": "2019-10-09T01:43:15.542916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready line: 6450-10-0\n"
     ]
    }
   ],
   "source": [
    "selected_line = ['8700-10-1']\n",
    "\n",
    "'8700-10-0',\n",
    "selected_line = ['8700-10-1',                \n",
    "                '7545-10-1',\n",
    "                '7545-10-0',\n",
    "                '6450-10-1',\n",
    "                '6450-10-0',\n",
    "                '3301-10-1',\n",
    "#                 '3301-10-0',\n",
    "                '2290-10-1',\n",
    "                '2290-10-0',\n",
    "#                 '574J-10-1',\n",
    "#                 '574J-10-0',\n",
    "#                 '477P-10-1',\n",
    "                '477P-10-0',\n",
    "#                 '351F-10-1',\n",
    "#                 '351F-10-0'\n",
    "                ]\n",
    "\n",
    "selected_line = ['6450-10-0']\n",
    "\n",
    "pth_files_GTFS = \"../data/gtfs/\"\n",
    "\n",
    "trips = pd.read_csv(pth_files_GTFS + 'trips.txt', sep=',')\n",
    "shapes = pd.read_csv(pth_files_GTFS + 'shapes.txt', sep=',')\n",
    "stops = pd.read_csv(pth_files_GTFS + 'stops.txt', sep=',')\n",
    "stopid = pd.read_csv(pth_files_GTFS + 'stop_times.txt', sep=',')   \n",
    "\n",
    "periods = ['morning', 'm_peak', 'i_peak', 'a_peak', 'night']\n",
    "\n",
    "MAPE_day = []\n",
    "for line in selected_line:\n",
    "#     line = selected_line[0]\n",
    "    p, mp = stops_distance(line)\n",
    "    pth_files_lines = \"../historical/readData/\"\n",
    "\n",
    "    ### Operação demorada\n",
    "    df, reps = read(pth_files_lines + \"trips_\" + line + \".dsk\", pth_files_lines + \"interps_\" + line + \".rep\")\n",
    "\n",
    "    df['day'] = pd.to_datetime(df['day'], format = '%Y-%m-%d')\n",
    "    df['start'] = pd.to_datetime(df['start'], format = '%H:%M:%S')\n",
    "    \n",
    "    start_date = datetime.date(2017, 9, 1)       \n",
    "    end_date = datetime.date(2017, 9, 28)        \n",
    "\n",
    "    df = df.loc[((df['day'] >= start_date) & (df['holiday'] != 1)) & ((df['weekday'] != 6) & (df['weekday'] != 5) & (df['weekday'] != 4) & (df['weekday'] != 0))]\n",
    "\n",
    "#     end_date = datetime.date(2017, 9, 28)        \n",
    "#     df = df.loc[((df['day'] >= end_date) & (df['holiday'] != 1)) & ((df['weekday'] != 6) & (df['weekday'] != 5) & (df['weekday'] != 4) & (df['weekday'] != 0))]\n",
    "\n",
    "    df['exact_time'] = np.array(df['day'], dtype='datetime64[ns]') + \\\n",
    "                        pd.to_timedelta(pd.to_timedelta(pd.DatetimeIndex(df['start']).hour*60 + \\\n",
    "                        pd.DatetimeIndex(df['start']).minute + \\\n",
    "                        pd.DatetimeIndex(df['start']).second/60 + \\\n",
    "                        df['time'], unit='m'))\n",
    "\n",
    "    df.index = df['exact_time']\n",
    "    df['day_hour'] = df['exact_time'].apply(hr_func)\n",
    "\n",
    "    df['link'] = 0\n",
    "    for i in range(0, len(mp)):\n",
    "        if (i == 0):\n",
    "              df.loc[df.loc[(df['distance'] > 0) & (df['distance'] < mp[i+1]),]['link'].index,'link'] = i    \n",
    "        if (i == len(mp) -1):\n",
    "            df.loc[df.loc[(df['distance'] > mp[i]) & (df['distance'] < max(p)),]['link'].index,'link'] = i    \n",
    "        if (i != 0) & (i != len(mp)-1):\n",
    "            df.loc[df.loc[(df['distance'] >= mp[i]) & (df['distance'] < mp[i+1]),]['link'].index,'link'] = i    \n",
    "\n",
    "    df = df.drop_duplicates(subset=['day', 'numtravel', 'link', 'day_hour'])   \n",
    "\n",
    "    link_df = []\n",
    "    travels = sorted(list(set(df.numtravel.unique())))\n",
    "    for tr in travels:\n",
    "        tck = reps[tr][0]\n",
    "        tck_mods = [(tck[0],tck[1]-m,tck[2]) for m in mp]       \n",
    "        tempo = [a[0] if a.size>0 else np.nan for a in [interpolate.sproot(tck_mod) for tck_mod in tck_mods]]\n",
    "        row = [tuple([tempo[i+1]-pos for i, pos in enumerate(tempo[:-1])])]    \n",
    "        link_df.append(row)      \n",
    "\n",
    "    # data_training['time_link'] = 0 \n",
    "    link_df_np = np.array(link_df)\n",
    "    link_df_np.shape = (np.shape(link_df_np)[0] * np.shape(link_df_np)[2])\n",
    "\n",
    "    # df['time_link'] = 0\n",
    "\n",
    "    right = pd.DataFrame({'numtravel': np.repeat(df.numtravel.unique(), len(mp)-1), \\\n",
    "                  'link': np.tile(range(0, len(mp)-1), len(df.numtravel.unique())), \n",
    "                  'time_link': link_df_np}) \n",
    "\n",
    "    df_merged = pd.merge(right, df, how='right', on=['numtravel', 'link'])    \n",
    "    \n",
    "    df_merged.index = df_merged['exact_time']\n",
    "\n",
    "    ML_data = df_merged.loc[df_merged['link'] < (np.max(df_merged['link']) - 1)]\n",
    "\n",
    "\n",
    "    ML_data = ML_data.groupby([pd.Grouper(freq='30min'), 'link'], as_index=True ).median()['time_link'].unstack()\\\n",
    "        .rolling(1).mean().transform(lambda x: x.fillna(method='ffill')).dropna()\n",
    "\n",
    "    ML_data = ML_data.iloc[ML_data.index.indexer_between_time('08:00', '23:00')].reset_index()\n",
    "\n",
    "    ML_data_train = ML_data.loc[(ML_data['exact_time'] < end_date)]\n",
    "    ML_data_test = ML_data.loc[(ML_data['exact_time'] >= end_date)]\n",
    "\n",
    "    train_x = ML_data_train.iloc[:(np.shape(ML_data_train)[0] -1),:]\n",
    "    train_y = ML_data_train.iloc[1:,:]\n",
    "\n",
    "\n",
    "    test_x = ML_data_test.iloc[:(np.shape(ML_data_test)[0] -1),:]\n",
    "    test_y = ML_data_test.iloc[1:,:]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model_tree = tree.DecisionTreeRegressor()\n",
    "    model_lasso = Lasso(alpha=0.1)  \n",
    "    \n",
    "    model.fit(train_x.drop(['exact_time'], axis=1), train_y.drop(['exact_time'], axis=1))    \n",
    "    pred_y_after = model.predict(test_x.drop(['exact_time'], axis=1))    \n",
    "    \n",
    "    model_tree.fit(train_x.drop(['exact_time'], axis=1), train_y.drop(['exact_time'], axis=1))    \n",
    "    pred_y_after_tree = model_tree.predict(test_x.drop(['exact_time'], axis=1))    \n",
    "    \n",
    "    \n",
    "    model_lasso.fit(train_x.drop(['exact_time'], axis=1), train_y.drop(['exact_time'], axis=1))    \n",
    "    pred_y_after_lasso = model_lasso.predict(test_x.drop(['exact_time'], axis=1))    \n",
    "    \n",
    "    pred_y_after = pd.DataFrame(pred_y_after)\n",
    "    pred_y_after.index = test_x['exact_time']\n",
    "    \n",
    "    pred_y_after_tree = pd.DataFrame(pred_y_after_tree)\n",
    "    pred_y_after_tree.index = test_x['exact_time']    \n",
    "    \n",
    "    pred_y_after_lasso = pd.DataFrame(pred_y_after_lasso)\n",
    "    pred_y_after_lasso.index = test_x['exact_time']    \n",
    "    \n",
    "    ### 2 times after data  \n",
    "    \n",
    "    train_x = ML_data_train.iloc[:(np.shape(ML_data_train)[0] - 2),:]\n",
    "    train_y = ML_data_train.iloc[2:,:]\n",
    "\n",
    "\n",
    "    test_x = ML_data_test.iloc[:(np.shape(ML_data_test)[0] - 2),:]\n",
    "    test_y = ML_data_test.iloc[2:,:]\n",
    "    \n",
    "    \n",
    "    model.fit(train_x.drop(['exact_time'], axis=1), train_y.drop(['exact_time'], axis=1))    \n",
    "    pred_y_future = model.predict(test_x.drop(['exact_time'], axis=1))\n",
    "    \n",
    "    model_tree.fit(train_x.drop(['exact_time'], axis=1), train_y.drop(['exact_time'], axis=1))    \n",
    "    pred_y_future_tree = model_tree.predict(test_x.drop(['exact_time'], axis=1))   \n",
    "    \n",
    "    model_lasso.fit(train_x.drop(['exact_time'], axis=1), train_y.drop(['exact_time'], axis=1))    \n",
    "    pred_y_future_lasso = model_lasso.predict(test_x.drop(['exact_time'], axis=1))\n",
    "     \n",
    "    pred_y_future = pd.DataFrame(pred_y_future)\n",
    "    pred_y_future.index = test_x['exact_time']   \n",
    "    \n",
    "    pred_y_future_tree = pd.DataFrame(pred_y_future_tree)\n",
    "    pred_y_future_tree.index = test_x['exact_time']\n",
    "\n",
    "    pred_y_future_lasso = pd.DataFrame(pred_y_future_lasso)\n",
    "    pred_y_future_lasso.index = test_x['exact_time']\n",
    "  \n",
    "    ### per travel verification\n",
    "\n",
    "    travel_times = pd.DataFrame(np.reshape(link_df, (np.shape(link_df)[0], np.shape(link_df)[2])))\n",
    "    travel_times.index = travels\n",
    "\n",
    "    MAPE_array = []\n",
    "    for select_day in df.day.dt.strftime('%Y-%m-%d').unique():\n",
    "        \n",
    "        for link in range(1, len(mp)-3):\n",
    "            df_temp = df.loc[(df['day'] == select_day) & (df['link'] == link)]\n",
    "            # travels_day = np.unique(np.array(df_temp['numtravel']))\n",
    "\n",
    "            for hour_day in range(640, 1200, 60):   \n",
    "                int_part, float_part = divmod((hour_day/60), 1)\n",
    "\n",
    "                hour_begin = str(int(int_part)) + ':' + '00'\n",
    "                hour_end = str(int(int_part + 1 )) + ':' + '00'\n",
    "                hour_test = str(int(int_part +  2)) + ':' + '00'\n",
    "                hour_future = str(int(int_part +  3)) + ':' + '00'\n",
    "                \n",
    "                df_temp_time = df_temp.iloc[df_temp.index.indexer_between_time( hour_begin, hour_end)]\n",
    "                df_temp_test = df_temp.iloc[df_temp.index.indexer_between_time( hour_end, hour_test)]\n",
    "                df_temp_future = df_temp.iloc[df_temp.index.indexer_between_time(hour_test, hour_future)]               \n",
    "                \n",
    "                temp_travels_time = travel_times.loc[np.unique(np.array(df_temp_time['numtravel']))][link]\n",
    "                time_tests        = travel_times.loc[np.unique(np.array(df_temp_test['numtravel']))][link]\n",
    "                time_future       = travel_times.loc[np.unique(np.array(df_temp_future['numtravel']))][link]\n",
    "                \n",
    "                median_test = np.median(temp_travels_time)\n",
    "                \n",
    "                median_LR_after = np.array(pred_y_after.iloc[pred_y_after.index.indexer_between_time(hour_test, hour_test)][link])\n",
    "                median_LR_future = np.array(pred_y_future.iloc[pred_y_future.index.indexer_between_time(hour_future, hour_future)][link])\n",
    "                \n",
    "                median_Tree_after = np.array(pred_y_after_tree.iloc[pred_y_after_tree.index.indexer_between_time(hour_test, hour_test)][link])\n",
    "                median_Tree_future = np.array(pred_y_future_tree.iloc[pred_y_future_tree.index.indexer_between_time(hour_future, hour_future)][link])\n",
    "                \n",
    "                median_Lasso_after = np.array(pred_y_after_lasso.iloc[pred_y_after_lasso.index.indexer_between_time(hour_test, hour_test)][link])\n",
    "                median_Lasso_future = np.array(pred_y_future_lasso.iloc[pred_y_future_lasso.index.indexer_between_time(hour_future, hour_future)][link])\n",
    "                \n",
    "                if ((len(temp_travels_time) > 0) & (math.isnan(median_test) == False)):\n",
    "                    MAPE_day.append([line, link, select_day, hour_begin + ' - ' + hour_end, len(temp_travels_time), median_test,\n",
    "                         mean_absolute_percentage_error([median_test]*len(temp_travels_time), temp_travels_time), \n",
    "                         str(np.array(temp_travels_time)), 'Actual'])\n",
    "         \n",
    "                \n",
    "                if (len(time_tests) > 0) & (math.isnan(median_test) == False) & (np.isnan(time_tests).any() == False):\n",
    "                    MAPE_array.append(mean_absolute_percentage_error([median_test]*len(time_tests), time_tests))\n",
    "                    \n",
    "                    \n",
    "                    MAPE_day.append([line, link, select_day, hour_end + ' - ' + hour_test, len(time_tests), median_test,\n",
    "                                     mean_absolute_percentage_error([median_test]*len(time_tests), time_tests), \n",
    "                                     str(np.array(time_tests)), 'After'])\n",
    "                    \n",
    "                    MAPE_day.append([line, link, select_day, hour_end + ' - ' + hour_test, len(hour_test), median_LR_after,\n",
    "                             mean_absolute_percentage_error([median_LR_after]*len(time_tests), time_tests), \n",
    "                             str(np.array(time_tests)), 'median_LR_after'])\n",
    "                    \n",
    "                    MAPE_day.append([line, link, select_day, hour_end + ' - ' + hour_test, len(hour_test), median_Tree_after,\n",
    "                             mean_absolute_percentage_error([median_Tree_after]*len(time_tests), time_tests), \n",
    "                             str(np.array(time_tests)), 'median_Tree_after'])\n",
    "                    \n",
    "                    MAPE_day.append([line, link, select_day, hour_end + ' - ' + hour_test, len(hour_test), median_Lasso_after,\n",
    "                             mean_absolute_percentage_error([median_Lasso_after]*len(time_tests), time_tests), \n",
    "                             str(np.array(time_tests)), 'median_Lasso_after'])\n",
    "                    \n",
    "                if (len(time_future) > 0) & (math.isnan(median_test) == False) & (np.isnan(time_future).any() == False):\n",
    "                    MAPE_day.append([line, link, select_day, hour_test + ' - ' + hour_future, len(time_future), median_test,\n",
    "                                     mean_absolute_percentage_error([median_test]*len(time_future), time_future), \n",
    "                                     str(np.array(time_future)), 'Future'])\n",
    "                    \n",
    "                    MAPE_day.append([line, link, select_day, hour_test + ' - ' + hour_future, len(time_future), median_LR_after,\n",
    "                                     mean_absolute_percentage_error([median_LR_after]*len(time_future), time_future), \n",
    "                                     str(np.array(time_future)), 'median_LR_future'])\n",
    "                    \n",
    "                    MAPE_day.append([line, link, select_day, hour_test + ' - ' + hour_future, len(time_future), median_Tree_future,\n",
    "                                     mean_absolute_percentage_error([median_Tree_future]*len(time_future), time_future), \n",
    "                                     str(np.array(time_future)), 'median_Tree_future'])\n",
    "                    \n",
    "                    MAPE_day.append([line, link, select_day, hour_test + ' - ' + hour_future, len(time_future), median_Tree_future,\n",
    "                                     mean_absolute_percentage_error([median_Tree_future]*len(time_future), time_future), \n",
    "                                     str(np.array(time_future)), 'median_Tree_future'])\n",
    "                    \n",
    "                    MAPE_day.append([line, link, select_day, hour_test + ' - ' + hour_future, len(time_future), median_Lasso_future,\n",
    "                                     mean_absolute_percentage_error([median_Lasso_future]*len(time_future), time_future), \n",
    "                                     str(np.array(time_future)), 'median_Lasso_future'])\n",
    "    \n",
    "                    \n",
    "    \n",
    "    print('Ready line: ' + line )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:47:14.282438Z",
     "start_time": "2019-10-09T01:46:59.379110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual : 10.60633630861167\n",
      "After : 15.413266513636533\n",
      "median_LR_after : 14.588977528393583\n",
      "median_Tree_after : 21.578564789031116\n",
      "median_Lasso_after : 14.467570324018032\n",
      "Future : 18.319616488348224\n",
      "median_LR_future : 14.335110099378415\n",
      "median_Tree_future : 17.79166852908641\n",
      "median_Lasso_future : 14.83445000947186\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(MAPE_day,columns=['line', 'link', 'day', 'time', 'N-travel', 'median', 'MAPE', 'travels_time', 'errors'])\n",
    "pd.DataFrame(data).to_html('html/data-60M_median_'  + select_day + '.html')  \n",
    "        \n",
    "data = data.loc[data['MAPE'] != 0] \n",
    "# data.loc[(data['errors'] != 'median_LR_after') & (data['errors'] != 'median_Tree_after') &\n",
    "#         (data['errors'] != 'median_LR_future') & (data['errors'] != 'median_Tree_future')]\n",
    "fig = (\n",
    "        p9.ggplot(data, p9.aes(x = 'errors', y ='MAPE', group='errors', colors='errors')) +\n",
    "        p9.geom_boxplot( outlier_shape = \"\") +\n",
    "        p9.scale_y_continuous(limits =  (0, 50)) +        \n",
    "        p9.stat_boxplot(geom ='errorbar')  +        \n",
    "        p9.theme_bw() +\n",
    "        p9.theme(figure_size = (8, 12)) +\n",
    "        p9.facet_wrap('~line', ncol = 3) +\n",
    "        p9.labs(title = 'MAPE of the lines in the day ' + select_day ) +\n",
    "        p9.theme(figure_size = (9, 12)) +\n",
    "        p9.theme(axis_text_x = p9.element_text(angle=90)) \n",
    "    )\n",
    "p9.ggsave(fig, 'png/Boxplot' + '_' + select_day + '_60M_median.png')  \n",
    "p9.ggsave(fig, 'pdf/Boxplot' + '_' + select_day + '_60M_median.pdf')  \n",
    "\n",
    "for i in data['errors'].unique():\n",
    "    print(i + ' : ' + str(data.loc[data['errors'] == i]['MAPE'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:03:58.495143Z",
     "start_time": "2019-06-17T02:03:58.480557Z"
    }
   },
   "source": [
    "# Using the Mean of $n$ buses in a period of 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T04:38:25.592597Z",
     "start_time": "2019-08-01T04:37:26.943473Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_line = ['8700-10-1']\n",
    "\n",
    "selected_line = ['8700-10-1',                \n",
    "                '7545-10-1',\n",
    "                '7545-10-0',\n",
    "                '6450-10-1',\n",
    "                '6450-10-0',\n",
    "                '3301-10-1',\n",
    "#                 '3301-10-0',\n",
    "                '2290-10-1',\n",
    "                '2290-10-0',\n",
    "#                 '574J-10-1',\n",
    "#                 '574J-10-0',\n",
    "#                 '477P-10-1',\n",
    "                '477P-10-0',\n",
    "#                 '351F-10-1',\n",
    "#                 '351F-10-0'\n",
    "                ]\n",
    "\n",
    "pth_files_GTFS = \"../historical/readData/dados/gtfs/\"\n",
    "\n",
    "trips = pd.read_csv(pth_files_GTFS + 'trips.txt', sep=',')\n",
    "shapes = pd.read_csv(pth_files_GTFS + 'shapes.txt', sep=',')\n",
    "stops = pd.read_csv(pth_files_GTFS + 'stops.txt', sep=',')\n",
    "stopid = pd.read_csv(pth_files_GTFS + 'stop_times.txt', sep=',')   \n",
    "\n",
    "periods = ['morning', 'm_peak', 'i_peak', 'a_peak', 'night']\n",
    "\n",
    "for line in selected_line:\n",
    "#     line = selected_line[0]\n",
    "    p, mp = stops_distance(line)\n",
    "    pth_files_lines = \"../historical/readData/\"\n",
    "\n",
    "    ### Operação demorada\n",
    "    df, reps = read(pth_files_lines + \"trips_\" + line + \".dsk\", pth_files_lines + \"interps_\" + line + \".rep\")\n",
    "\n",
    "    df['day'] = pd.to_datetime(df['day'], format = '%Y-%m-%d')\n",
    "    df['start'] = pd.to_datetime(df['start'], format = '%H:%M:%S')\n",
    "\n",
    "    end_date = datetime.date(2017, 9, 1)        \n",
    "\n",
    "    df = df.loc[((df['day'] >= end_date) & (df['holiday'] != 1)) & ((df['weekday'] != 6) & (df['weekday'] != 5) & (df['weekday'] != 4) & (df['weekday'] != 0))]\n",
    "\n",
    "    df['exact_time'] = np.array(df['day'], dtype='datetime64[ns]') + \\\n",
    "                        pd.to_timedelta(pd.to_timedelta(pd.DatetimeIndex(df['start']).hour*60 + \\\n",
    "                        pd.DatetimeIndex(df['start']).minute + \\\n",
    "                        pd.DatetimeIndex(df['start']).second/60 + \\\n",
    "                        df['time'], unit='m'))\n",
    "\n",
    "    df.index = df['exact_time']\n",
    "    df.iloc[df.index.indexer_between_time('08:00', '20:00')]\n",
    "\n",
    "    df['day_hour'] = df['exact_time'].apply(hr_func)\n",
    "\n",
    "    df['link'] = 0\n",
    "    for i in range(0, len(mp)):\n",
    "        if (i == 0):\n",
    "              df.loc[df.loc[(df['distance'] > 0) & (df['distance'] < mp[i+1]),]['link'].index,'link'] = i    \n",
    "        if (i == len(mp) -1):\n",
    "            df.loc[df.loc[(df['distance'] > mp[i]) & (df['distance'] < max(p)),]['link'].index,'link'] = i    \n",
    "        if (i != 0) & (i != len(mp)-1):\n",
    "            df.loc[df.loc[(df['distance'] >= mp[i]) & (df['distance'] < mp[i+1]),]['link'].index,'link'] = i    \n",
    "\n",
    "    df = df.drop_duplicates(subset=['day', 'numtravel', 'link', 'day_hour'])   \n",
    "\n",
    "    link_df = []\n",
    "    travels = sorted(list(set(df.numtravel.unique())))\n",
    "    for tr in travels:\n",
    "        tck = reps[tr][0]\n",
    "        tck_mods = [(tck[0],tck[1]-m,tck[2]) for m in mp]       \n",
    "        tempo = [a[0] if a.size>0 else np.nan for a in [interpolate.sproot(tck_mod) for tck_mod in tck_mods]]\n",
    "        row = [tuple([tempo[i+1]-pos for i, pos in enumerate(tempo[:-1])])]    \n",
    "        link_df.append(row)\n",
    "\n",
    "    travel_times = pd.DataFrame(np.reshape(link_df, (np.shape(link_df)[0], np.shape(link_df)[2])))\n",
    "    travel_times.index = travels\n",
    "\n",
    "    MAPE_array = []\n",
    "\n",
    "    for select_day in df.day.dt.strftime('%Y-%m-%d').unique():\n",
    "        MAPE_day = []\n",
    "        for link in range(1, len(mp)-2):\n",
    "            df_temp = df.loc[(df['day'] == select_day) & (df['link'] == link)]\n",
    "            # travels_day = np.unique(np.array(df_temp['numtravel']))\n",
    "\n",
    "            for hour_day in range(640, 1320, 30):   \n",
    "                int_part, float_part = divmod((hour_day/60), 1)\n",
    "\n",
    "                if float_part != 0:\n",
    "                    hour_begin = str(int(int_part)) + ':' + '30'\n",
    "                    hour_end = str(int(int_part + 1 )) + ':' + '00'\n",
    "                    hour_test = str(int(int_part + 1 )) + ':' + '30'\n",
    "                else:\n",
    "                    hour_begin = str(int(int_part)) + ':' + '00'\n",
    "                    hour_end = str(int(int_part)) + ':' + '30'\n",
    "                    hour_test = str(int(int_part + 1 )) + ':' + '00'\n",
    "\n",
    "                df_temp_time = df_temp.iloc[df_temp.index.indexer_between_time( hour_begin, hour_end)]\n",
    "                df_temp_test = df_temp.iloc[df_temp.index.indexer_between_time( hour_end, hour_test)]\n",
    "                \n",
    "                temp_travels_time = travel_times.loc[np.unique(np.array(df_temp_time['numtravel']))][link]\n",
    "                \n",
    "                median_test = np.mean(temp_travels_time)\n",
    "                time_tests = travel_times.loc[np.unique(np.array(df_temp_test['numtravel']))][link]\n",
    "                \n",
    "                if ((len(temp_travels_time) > 0) & (math.isnan(median_test) == False)):\n",
    "                    MAPE_day.append([link, float(format(hour_day/60, '.1f')), len(temp_travels_time), median_test,\n",
    "                         mean_absolute_percentage_error([median_test]*len(temp_travels_time), temp_travels_time), \n",
    "                         str(np.array(temp_travels_time)), 'actual'])\n",
    "#                     print(str(link) + \"-\" + str(hour_day) + \":\" + str(mean_absolute_percentage_error([median_test]*len(time_tests), time_tests)) + \"\\n\")\n",
    "                \n",
    "         \n",
    "                \n",
    "                if (len(time_tests) > 0) & (math.isnan(median_test) == False) & (np.isnan(time_tests).any() == False):\n",
    "                    MAPE_array.append(mean_absolute_percentage_error([median_test]*len(time_tests), time_tests))\n",
    "                    \n",
    "                    \n",
    "                    MAPE_day.append([link, float(format(hour_day/60, '.1f')), len(temp_travels_time), median_test,\n",
    "                                     mean_absolute_percentage_error([median_test]*len(time_tests), time_tests), \n",
    "                                     str(np.array(time_tests)), 'after'])\n",
    "\n",
    "\n",
    "\n",
    "            data = pd.DataFrame(MAPE_day,columns=['link', 'time', 'N-travel', 'median', 'MAPE', 'travels_time', 'errors'])\n",
    "        pd.DataFrame(data).to_html('html/data-30M_mean_' + line + '_' + select_day + '.html')  \n",
    "        \n",
    "        if not data.empty:        \n",
    "            fig = (\n",
    "                p9.ggplot(data) +\n",
    "                p9.geom_line(\n",
    "                    p9.aes(x = 'time', y ='MAPE', group='errors', color='errors')\n",
    "                ) +\n",
    "                p9.theme_bw() +\n",
    "                p9.theme(figure_size = (8, 12)) +\n",
    "                p9.facet_wrap('~link', ncol = 6) +\n",
    "                p9.labs(\n",
    "                    title = 'MAPE of the line '  + line + ' in the day ' + select_day \n",
    "                ) +\n",
    "                p9.theme(figure_size = (18, 24)) \n",
    "            )\n",
    "            p9.ggsave(fig, 'png/' + line + '_' + select_day + '_30M_mean.png')\n",
    "\n",
    "            fig = (\n",
    "                p9.ggplot(data) +\n",
    "                p9.geom_line(\n",
    "                    p9.aes(x = 'time', y ='MAPE', group='errors', color='errors')\n",
    "                ) +\n",
    "                p9.theme_bw() +\n",
    "                p9.theme(figure_size = (8, 12)) +\n",
    "                p9.facet_wrap('~link', ncol = 6, scales = \"free_y\") +\n",
    "                p9.labs(\n",
    "                    title = 'MAPE of the line '  + line + ' in the day ' + select_day \n",
    "                ) +\n",
    "                p9.theme(figure_size = (18, 24)) \n",
    "            )\n",
    "            p9.ggsave(fig, 'png/' + line + '_' + select_day + '_30M_mean_free-Y.png') \n",
    "            \n",
    "    MAPE_array = np.array(MAPE_array)\n",
    "    print(line + ' MAPE(all) = ' + str(format(np.mean(MAPE_array), '.2f')) + '%')\n",
    "\n",
    "    median_fig, ax = plt.subplots()\n",
    "    ax.set_title(line + ' - mean = ' + str(format(np.mean(MAPE_array), '.2f')) + '%')\n",
    "    ax.boxplot(MAPE_array, notch=True)\n",
    "    median_fig.savefig(line + '_mean_last_30MIN_all.png' )\n",
    "\n",
    "\n",
    "    MAPE_array = MAPE_array[MAPE_array < 50]\n",
    "    print(line + ' MAPE(Thresh>5) = ' + str(format(np.mean(MAPE_array), '.2f')) + '%')\n",
    "    \n",
    "\n",
    "    median_fig, ax = plt.subplots()\n",
    "    ax.set_title(line + ' - mean = ' + str(format(np.mean(MAPE_array), '.2f')) + '%')\n",
    "    ax.boxplot(MAPE_array, notch=True)\n",
    "    median_fig.savefig(line + '_mean_last_30MIN_MAPE-threshold.png' )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-08T14:22:57.831Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_line = ['8700-10-1']\n",
    "\n",
    "'8700-10-0',\n",
    "selected_line = ['8700-10-1',                \n",
    "                '7545-10-1',\n",
    "                '7545-10-0',\n",
    "                '6450-10-1',\n",
    "                '6450-10-0',\n",
    "                '3301-10-1',\n",
    "#                 '3301-10-0',\n",
    "                '2290-10-1',\n",
    "                '2290-10-0',\n",
    "#                 '574J-10-1',\n",
    "#                 '574J-10-0',\n",
    "#                 '477P-10-1',\n",
    "                '477P-10-0',\n",
    "#                 '351F-10-1',\n",
    "#                 '351F-10-0'\n",
    "                ]\n",
    "\n",
    "\n",
    "pth_files_GTFS = \"../historical/readData/dados/gtfs/\"\n",
    "\n",
    "trips = pd.read_csv(pth_files_GTFS + 'trips.txt', sep=',')\n",
    "shapes = pd.read_csv(pth_files_GTFS + 'shapes.txt', sep=',')\n",
    "stops = pd.read_csv(pth_files_GTFS + 'stops.txt', sep=',')\n",
    "stopid = pd.read_csv(pth_files_GTFS + 'stop_times.txt', sep=',')   \n",
    "\n",
    "periods = ['morning', 'm_peak', 'i_peak', 'a_peak', 'night']\n",
    "\n",
    "for line in selected_line:\n",
    "#     line = selected_line[0]\n",
    "    p, mp = stops_distance(line)\n",
    "    pth_files_lines = \"../historical/readData/\"\n",
    "\n",
    "    ### Operação demorada\n",
    "    df, reps = read(pth_files_lines + \"trips_\" + line + \".dsk\", pth_files_lines + \"interps_\" + line + \".rep\")\n",
    "\n",
    "    df['day'] = pd.to_datetime(df['day'], format = '%Y-%m-%d')\n",
    "    df['start'] = pd.to_datetime(df['start'], format = '%H:%M:%S')\n",
    "\n",
    "    end_date = datetime.date(2017, 9, 1)        \n",
    "\n",
    "    df = df.loc[((df['day'] >= end_date) & (df['holiday'] != 1)) & ((df['weekday'] != 6) & (df['weekday'] != 5) & (df['weekday'] != 4) & (df['weekday'] != 0))]\n",
    "\n",
    "    df['exact_time'] = np.array(df['day'], dtype='datetime64[ns]') + \\\n",
    "                        pd.to_timedelta(pd.to_timedelta(pd.DatetimeIndex(df['start']).hour*60 + \\\n",
    "                        pd.DatetimeIndex(df['start']).minute + \\\n",
    "                        pd.DatetimeIndex(df['start']).second/60 + \\\n",
    "                        df['time'], unit='m'))\n",
    "\n",
    "    df.index = df['exact_time']\n",
    "    df.iloc[df.index.indexer_between_time('08:00', '20:00')]\n",
    "\n",
    "    df['day_hour'] = df['exact_time'].apply(hr_func)\n",
    "\n",
    "    df['link'] = 0\n",
    "    for i in range(0, len(mp)):\n",
    "        if (i == 0):\n",
    "              df.loc[df.loc[(df['distance'] > 0) & (df['distance'] < mp[i+1]),]['link'].index,'link'] = i    \n",
    "        if (i == len(mp) -1):\n",
    "            df.loc[df.loc[(df['distance'] > mp[i]) & (df['distance'] < max(p)),]['link'].index,'link'] = i    \n",
    "        if (i != 0) & (i != len(mp)-1):\n",
    "            df.loc[df.loc[(df['distance'] >= mp[i]) & (df['distance'] < mp[i+1]),]['link'].index,'link'] = i    \n",
    "\n",
    "    df = df.drop_duplicates(subset=['day', 'numtravel', 'link', 'day_hour'])   \n",
    "\n",
    "    link_df = []\n",
    "    travels = sorted(list(set(df.numtravel.unique())))\n",
    "    for tr in travels:\n",
    "        tck = reps[tr][0]\n",
    "        tck_mods = [(tck[0],tck[1]-m,tck[2]) for m in mp]       \n",
    "        tempo = [a[0] if a.size>0 else np.nan for a in [interpolate.sproot(tck_mod) for tck_mod in tck_mods]]\n",
    "        row = [tuple([tempo[i+1]-pos for i, pos in enumerate(tempo[:-1])])]    \n",
    "        link_df.append(row)\n",
    "\n",
    "    travel_times = pd.DataFrame(np.reshape(link_df, (np.shape(link_df)[0], np.shape(link_df)[2])))\n",
    "    travel_times.index = travels\n",
    "\n",
    "    MAPE_array = []\n",
    "\n",
    "    for select_day in df.day.dt.strftime('%Y-%m-%d').unique():\n",
    "        MAPE_day = []\n",
    "        for link in range(1, len(mp)-2):\n",
    "            df_temp = df.loc[(df['day'] == select_day) & (df['link'] == link)]\n",
    "            # travels_day = np.unique(np.array(df_temp['numtravel']))\n",
    "\n",
    "            for hour_day in range(640, 1320, 60):   \n",
    "                int_part, float_part = divmod((hour_day/60), 1)\n",
    "\n",
    "                hour_begin = str(int(int_part)) + ':' + '00'\n",
    "                hour_end = str(int(int_part + 1 )) + ':' + '00'\n",
    "                hour_test = str(int(int_part +  2)) + ':' + '00'\n",
    "                \n",
    "                df_temp_time = df_temp.iloc[df_temp.index.indexer_between_time( hour_begin, hour_end)]\n",
    "                df_temp_test = df_temp.iloc[df_temp.index.indexer_between_time( hour_end, hour_test)]\n",
    "                \n",
    "                temp_travels_time = travel_times.loc[np.unique(np.array(df_temp_time['numtravel']))][link]\n",
    "                \n",
    "                median_test = np.mean(temp_travels_time)\n",
    "                time_tests = travel_times.loc[np.unique(np.array(df_temp_test['numtravel']))][link]\n",
    "                \n",
    "                if ((len(temp_travels_time) > 0) & (math.isnan(median_test) == False)):\n",
    "                    MAPE_day.append([link, float(format(hour_day/60, '.1f')), len(temp_travels_time), median_test,\n",
    "                         mean_absolute_percentage_error([median_test]*len(temp_travels_time), temp_travels_time), \n",
    "                         str(np.array(temp_travels_time)), 'actual'])\n",
    "#                     print(str(link) + \"-\" + str(hour_day) + \":\" + str(mean_absolute_percentage_error([median_test]*len(time_tests), time_tests)) + \"\\n\")\n",
    "                \n",
    "         \n",
    "                \n",
    "                if (len(time_tests) > 0) & (math.isnan(median_test) == False) & (np.isnan(time_tests).any() == False):\n",
    "                    MAPE_array.append(mean_absolute_percentage_error([median_test]*len(time_tests), time_tests))\n",
    "                    \n",
    "                    \n",
    "                    MAPE_day.append([link, float(format(hour_day/60, '.1f')), len(temp_travels_time), median_test,\n",
    "                                     mean_absolute_percentage_error([median_test]*len(time_tests), time_tests), \n",
    "                                     str(np.array(time_tests)), 'after'])\n",
    "            \n",
    "            \n",
    "            data = pd.DataFrame(MAPE_day,columns=['link', 'time', 'N-travel', 'median', 'MAPE', 'travels_time', 'errors'])\n",
    "        pd.DataFrame(data).to_html('html/data-60M_mean_' + line + '_' + select_day + '.html')  \n",
    "        \n",
    "        if not data.empty:        \n",
    "            fig = (\n",
    "                p9.ggplot(data) +\n",
    "                p9.geom_line(\n",
    "                    p9.aes(x = 'time', y ='MAPE', group='errors', color='errors')\n",
    "                ) +\n",
    "                p9.theme_bw() +\n",
    "                p9.theme(figure_size = (8, 12)) +\n",
    "                p9.facet_wrap('~link', ncol = 6) +\n",
    "                p9.labs(\n",
    "                    title = 'MAPE of the line '  + line + ' in the day ' + select_day \n",
    "                ) +\n",
    "                p9.theme(figure_size = (18, 24)) \n",
    "            )\n",
    "            p9.ggsave(fig, 'png/' + line + '_' + select_day + '_60M_mean.png')\n",
    "\n",
    "            fig = (\n",
    "                p9.ggplot(data) +\n",
    "                p9.geom_line(\n",
    "                    p9.aes(x = 'time', y ='MAPE', group='errors', color='errors')\n",
    "                ) +\n",
    "                p9.theme_bw() +\n",
    "                p9.theme(figure_size = (8, 12)) +\n",
    "                p9.facet_wrap('~link', ncol = 6, scales = \"free_y\") +\n",
    "                p9.labs(\n",
    "                    title = 'MAPE of the line '  + line + ' in the day ' + select_day \n",
    "                ) +\n",
    "                p9.theme(figure_size = (18, 24)) \n",
    "            )\n",
    "            p9.ggsave(fig, 'png/' + line + '_' + select_day + '_60M_mean_free-Y.png')          \n",
    "\n",
    "    MAPE_array = np.array(MAPE_array)\n",
    "    print(line + ' MAPE(all) = ' + str(format(np.mean(MAPE_array), '.2f')) + '%')\n",
    "\n",
    "    median_fig, ax = plt.subplots()\n",
    "    ax.set_title(line + ' - mean = ' + str(format(np.mean(MAPE_array), '.2f')) + '%')\n",
    "    ax.boxplot(MAPE_array, notch=True)\n",
    "    median_fig.savefig(line + '_mean_last_60MIN_all.png' )\n",
    "\n",
    "\n",
    "    MAPE_array = MAPE_array[MAPE_array < 50]\n",
    "    print(line + ' MAPE(Thresh>5) = ' + str(format(np.mean(MAPE_array), '.2f')) + '%')\n",
    "    \n",
    "\n",
    "    median_fig, ax = plt.subplots()\n",
    "    ax.set_title(line + ' - mean = ' + str(format(np.mean(MAPE_array), '.2f')) + '%')\n",
    "    ax.boxplot(MAPE_array, notch=True)\n",
    "    median_fig.savefig(line + '_mean_last_60MIN_MAPE-threshold.png' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
